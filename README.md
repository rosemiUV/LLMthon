# ðŸš€ TP-Benchmark-AI: AutomatizaciÃ³n de Precios de Transferencia

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red)
![Playwright](https://img.shields.io/badge/RPA-Playwright-green)
![LLM](https://img.shields.io/badge/AI-OpenAI%2FGemini-orange)

## ðŸš€ CaracterÃ­sticas
- **Scraping Inteligente (Anti-Junk):** DetecciÃ³n automÃ¡tica de "dominios en venta" o pÃ¡ginas caÃ­das para ahorrar costes de API.
- **AnÃ¡lisis Cognitivo:** Un LLM audita la actividad de la empresa.
- **Evidencia Forense y Smart Highlighting:** Genera capturas de pantalla resaltando la razÃ³n del rechazo (ej. "Somos una filial...").
- **Anti-Bloqueos:** Arquitectura multiproceso para evadir detecciones y crashes.
- **SemÃ¡foro de Confianza:** El sistema marca en amarillo las filas donde la IA duda (<70% confianza) para revisiÃ³n humana.
- **ðŸ”— Trazabilidad Total:** El Excel de salida incluye hipervÃ­nculos locales directos a la evidencia grÃ¡fica.

## ðŸ› ï¸ InstalaciÃ³n
1. Instalar dependencias: `pip install -r requirements.txt`
2. Instalar navegadores: `playwright install`
3. Configurar `.env` con tu API Key.
4. Ejecutar: `streamlit run src/app.py`

## ðŸ—ï¸ Arquitectura
- **Frontend:** Streamlit
- **Core:** Python + Pandas
- **Scraper:** Playwright (Worker Mode)
- **AI:** Google Gemini

---

## ðŸ“‹ Contexto del Negocio

El proceso de **Benchmark de Precios de Transferencia** requiere validar manualmente cientos de empresas para determinar si son comparables al cliente objetivo. Esto implica verificar:
1.  **Independencia:** Â¿Es parte de un grupo empresarial?
2.  **FunciÃ³n:** Â¿Es manufacturera o prestadora de servicios?
3.  **Comparabilidad:** Â¿Ofrece los mismos servicios que nuestro cliente?

**TP-Benchmark-AI** reduce este proceso de semanas a minutos, generando un Excel auditado con **evidencias grÃ¡ficas (capturas de pantalla)** y razonamiento lÃ³gico detallado.

---


## ðŸŒŸ Crear entorno virtual

En anaconda prompt:

* mamba create -n tp-benchmark python=3.11 -y
* mamba activate tp-benchmark

---

## ðŸ‘¨â€ðŸ’» GuÃ­a de Desarrollo & Contratos de API (Squad Roles)

Para trabajar en paralelo sin romper el cÃ³digo del compaÃ±ero, cada integrante debe respetar estrictamente los siguientes formatos de entrada y salida (Interfaces).

---

### ðŸ•·ï¸ Rol 1: The Hunter (Web Scraping)
**Archivo:** `src/modules/scraper.py`
**Responsabilidad:** NavegaciÃ³n Headless, ExtracciÃ³n de texto y Capturas con Highlighting.

Debe implementar una clase `Scraper` con estas dos funciones independientes:

#### A. FunciÃ³n `extract_text(url)`
Extrae el texto limpio para enviarlo a la IA (Fase 1).
* **Input:** `url` (str)
* **Output:** Diccionario (JSON)

{
    "status": 200,            // CÃ³digo HTTP (404, 500, etc.)
    "is_junk": false,         // True si detecta "Domain for sale", "GoDaddy", etc.
    "text_content": "Texto completo y limpio de la web...",
    "error_msg": null         // String descriptivo si hubo error
}


## ðŸ‘¨â€ðŸ’» GuÃ­a de Desarrollo & Contratos de API (Squad Roles)

Para trabajar en paralelo sin romper el cÃ³digo del compaÃ±ero, cada integrante debe respetar estrictamente los siguientes formatos de entrada y salida (Interfaces).

#### B. FunciÃ³n take_screenshot(url, text_to_highlight)
Vuelve a navegar para sacar la "Foto de la Evidencia" (Fase 2).

* **Input**: url (str), text_to_highlight (str - Frase corta identificada por el LLM).

* **LÃ³gica**: Buscar la frase en el DOM -> Inyectar CSS (Borde rojo/amarillo) -> Sacar foto.

* **Output**: String (Path relativo a la imagen guardada).
"evidence/20231027_empresa_X.png"

---

### ðŸ§  Rol 2: The Analyst (LLM Engine)
**Archivo:** `src/modules/llm_engine.py`
**Responsabilidad:** Prompt Engineering y Parsing de JSON.

#### A. FunciÃ³n `analyze(text, client_description)`
* **Input**: text (str - viene del scraper), client_description (str - viene del usuario).

* **Output**: Diccionario JSON plano (Estricto).

```json
{
    "is_group": boolean,          // True si se debe rechazar por ser Grupo
    "is_manufacturer": boolean,   // True si se debe rechazar por Manufactura
    "service_match": boolean,     // True si los servicios coinciden
    "reasoning": "ExplicaciÃ³n breve de 1 lÃ­nea.",
    "evidence_quote": "Subsidiary of Omega Group",   // <--- VITAL: La frase exacta para el Highlighting
    "confidence_score": 95        // Entero 0-100
}

---

### ðŸ—ï¸ Rol 3: The Architect (Orchestration & UI)
**Archivo:** `src/app.py` y `src/core/orchestrator.py`
**Responsabilidad:**

* Unir las piezas (Scraper -> LLM -> Scraper -> Excel).
* Interfaz visual en Streamlit.

---

## ðŸ“‚ Estructura del Proyecto (Clean Architecture)

El proyecto sigue una arquitectura modular para desacoplar la interfaz, la lÃ³gica de negocio y los servicios externos.

```text
transfer-pricing-benchmark/
â”‚
â”œâ”€â”€ .env                     # Variables de entorno (API Keys)
â”œâ”€â”€ .gitignore               # Exclusiones de git
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â”œâ”€â”€ README.md                # DocumentaciÃ³n
â”‚
â”œâ”€â”€ data/                    # Almacenamiento temporal de datos
â”‚   â”œâ”€â”€ input/               # Lugar para "Matriz AR en blanco.xlsx"
â”‚   â””â”€â”€ output/              # Destino de "Matriz AR trabajada.xlsx"
â”‚
â”œâ”€â”€ evidence/                # Repositorio de capturas de pantalla
â”‚   â””â”€â”€ YYYYMMDD_HHMM/       # Subcarpetas por ejecuciÃ³n (Timestamp)
â”‚
â”œâ”€â”€ src/                     # CÃ³digo Fuente
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py               # Entry Point (Streamlit UI)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                # LÃ³gica de Negocio Central
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py  # Controlador del flujo (UI <-> Scraper <-> LLM)
â”‚   â”‚   â””â”€â”€ config.py        # Configuraciones globales y constantes
â”‚   â”‚
â”‚   â”œâ”€â”€ modules/             # Servicios Independientes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ excel_handler.py # Pandas/Openpyxl (Lectura/Escritura/Estilos)
â”‚   â”‚   â”œâ”€â”€ scraper.py       # Playwright (Nav, Screenshot, Highlighting)
â”‚   â”‚   â””â”€â”€ llm_engine.py    # IntegraciÃ³n API (Prompting & Parsing)
â”‚   â”‚
â”‚   â””â”€â”€ utils/               # Utilidades Transversales
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py        # Sistema de logging centralizado
â”‚       â””â”€â”€ helpers.py       # Limpieza de strings, fechas, validaciones
â”‚
â””â”€â”€ tests/                   # Unit tests y scripts de prueba rÃ¡pida
